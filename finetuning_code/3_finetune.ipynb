{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cf640-c387-4267-ad61-2737e83d01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"../../../../../../../../\")\n",
    "os.chdir(\"home/user/mnt/degelin/thesis\")\n",
    "sys.path.append(\"tune_sets/\")\n",
    "!pip install matplotlib==3.7.0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, InputExample, evaluation\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import torch.nn.functional as F\n",
    "#import transformers\n",
    "#import nltk\n",
    "#import gzip\n",
    "#import csv\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, handlers=[LoggingHandler()]\n",
    ")\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d59c431d-981f-4484-b7fa-b11e907d4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give file_name without '.csv'!\n",
    "def create_save_path(model_name):\n",
    "    if '/' in model_name:\n",
    "        model_name_parts = model_name.split('/')\n",
    "        model_name_save_path = '-'.join(model_name_parts)\n",
    "    else:\n",
    "        model_name_save_path = model_name\n",
    "    return model_name_save_path\n",
    "def truncate_text(text, max_length, tokenizer):\n",
    "    # Tokenize and encode the text, truncating to max_length\n",
    "    encoded = tokenizer.encode(text, max_length=max_length, truncation=True)\n",
    "    # Decode back to text\n",
    "    truncated_text = tokenizer.decode(encoded, skip_special_tokens=True)\n",
    "    # Double-check the encoded length\n",
    "    final_encoded = tokenizer.encode(truncated_text, max_length=max_length, truncation=True)\n",
    "    if len(final_encoded) > max_length:\n",
    "        print(f\"Warning: Truncated text still exceeds max length. Original length: {len(tokenizer.encode(text))}, Truncated length: {len(final_encoded)}\")\n",
    "        return None\n",
    "    return truncated_text\n",
    "def load_as_samples(file_name, max_length, tokenizer):\n",
    "    error_tokenizations = 0\n",
    "    base_path = 'tune_sets/llm/'\n",
    "    test_part = pd.read_csv(base_path + file_name + '_test_part.csv')\n",
    "    train_part = pd.read_csv(base_path + file_name + '_train_part.csv')\n",
    "    val_part = pd.read_csv(base_path + file_name + '_val_part.csv')\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    val_samples = []\n",
    "    for i in range(len(train_part)):\n",
    "        if i % 1000 == 0 :\n",
    "            print(\"processing i\", i)\n",
    "        # Check if 'PROJECT_TITLE' and 'grant_text' are not missing\n",
    "        text1 = train_part.iloc[i]['PROJECT_DESCRIPTION']\n",
    "        text2 = train_part.iloc[i]['GRANT_DESCRIPTION']\n",
    "        text1 = truncate_text(text1, max_length, tokenizer)\n",
    "        text2 = truncate_text(text2, max_length, tokenizer)\n",
    "        if text1 is None or text2 is None:\n",
    "            error_tokenizations +=1\n",
    "            continue\n",
    "        inp_example = InputExample(texts=[text1, text2], label=float(train_part.iloc[i]['label']))\n",
    "        train_samples.append(inp_example)\n",
    "    del train_part\n",
    "    for i in range(len(val_part)):\n",
    "        if i % 1000 == 0 :\n",
    "            print(\"processing i\", i)\n",
    "        # Check if 'PROJECT_TITLE' and 'grant_text' are not missing\n",
    "        text1 = val_part.iloc[i]['PROJECT_DESCRIPTION']\n",
    "        text2 = val_part.iloc[i]['GRANT_DESCRIPTION']\n",
    "        text1 = truncate_text(text1, max_length, tokenizer)\n",
    "        text2 = truncate_text(text2, max_length, tokenizer)\n",
    "        if text1 is None or text2 is None:\n",
    "            error_tokenizations +=1\n",
    "            continue\n",
    "        inp_example = InputExample(texts=[text1, text2], label=float(val_part.iloc[i]['label']))\n",
    "        val_samples.append(inp_example)\n",
    "    del val_part\n",
    "    for i in range(len(test_part)):\n",
    "        if i % 1000 == 0 :\n",
    "            print(\"processing i\", i)\n",
    "        # Check if 'PROJECT_TITLE' and 'grant_text' are not missing\n",
    "        text1 = test_part.iloc[i]['PROJECT_DESCRIPTION']\n",
    "        text2 = test_part.iloc[i]['GRANT_DESCRIPTION']\n",
    "        text1 = truncate_text(text1, max_length, tokenizer)\n",
    "        text2 = truncate_text(text2, max_length, tokenizer)\n",
    "        if text1 is None or text2 is None:\n",
    "            error_tokenizations +=1\n",
    "            continue\n",
    "        inp_example = InputExample(texts=[text1, text2], label=float(test_part.iloc[i]['label']))\n",
    "        test_samples.append(inp_example)\n",
    "    del test_part\n",
    "    return train_samples,val_samples,test_samples, error_tokenizations\n",
    "def fine_tune(model_name, file_name):\n",
    "    #!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu122\n",
    "    import torch\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Available devices:\")\n",
    "    print(torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    model_name_save_path = create_save_path(model_name)\n",
    "    model_save_path = (\n",
    "    \"good_code/fine_tuned_models/\" + file_name + \"/\" + \"fine_tuning-\" + model_name_save_path + \"-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    )\n",
    "    max_token_length = 255\n",
    "    original_model = SentenceTransformer(model_name)\n",
    "    fine_tuned_model = SentenceTransformer(model_name)\n",
    "    original_model.max_seq_length = max_token_length\n",
    "    fine_tuned_model.max_seq_length = max_token_length\n",
    "    tokenizer = original_model.tokenizer\n",
    "    train_batch_size = 32\n",
    "    num_epochs = 4\n",
    "    \n",
    "    eval_frequency = 0.1\n",
    "    train_samples,val_samples,test_samples, error_tokenizations = load_as_samples(file_name, max_token_length, tokenizer)\n",
    "    train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "    train_loss = losses.CosineSimilarityLoss(model=fine_tuned_model)\n",
    "    val_dataloader = DataLoader(val_samples, shuffle=False, batch_size=train_batch_size)\n",
    "    val_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(val_samples, name=\"validation\")\n",
    "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "    logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "    \n",
    "    steps_per_epoch = len(train_dataloader)\n",
    "    evaluation_steps = max(1, int(steps_per_epoch * eval_frequency))\n",
    "    logging.info(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "    logging.info(f\"Evaluation steps: {evaluation_steps}\")\n",
    "\n",
    "    print(\"Checking DataLoader\")\n",
    "    #for batch in train_dataloader:\n",
    "    #    print(\"Batch loaded:\", batch)\n",
    "    #    break\n",
    "    for param in fine_tuned_model.parameters():\n",
    "        param.data = param.data.contiguous()\n",
    "    fine_tuned_model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=val_evaluator,\n",
    "        epochs=num_epochs,\n",
    "        evaluation_steps=evaluation_steps,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path=model_save_path,\n",
    "    )\n",
    "    evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=\"model-evaluation\")\n",
    "    original_results = evaluator(original_model)\n",
    "    fine_tuned_results = evaluator(fine_tuned_model)\n",
    "    print(\"Original model results:\")\n",
    "    print(original_results)\n",
    "    print(\"Fine-tuned model results:\")\n",
    "    print(fine_tuned_results)\n",
    "    eval_path = os.path.join(model_save_path, 'eval')\n",
    "    save2_path = os.path.join(eval_path, 'original_vs_tuned.txt')\n",
    "    with open(save2_path, 'w') as file:\n",
    "        file.write(\"Original Model Results:\\n\")\n",
    "        file.write(f\"{original_results}\\n\\n\")\n",
    "        file.write(\"Fine-Tuned Model Results:\\n\")\n",
    "        file.write(f\"{fine_tuned_results}\\n\")\n",
    "        file.write(\"Error_tokenizations:\\n\")\n",
    "        file.write(f\"{error_tokenizations}\\n\")\n",
    "    \n",
    "    print(f\"Results saved to {save2_path}\")\n",
    "    # Extract labels from InputExample objects\n",
    "    true_labels = [example.label for example in test_samples]\n",
    "    \n",
    "    # Encode test sentences to obtain embeddings\n",
    "    test_embeddings_1 = fine_tuned_model.encode([example.texts[0] for example in test_samples], \n",
    "                                            convert_to_tensor=True)\n",
    "    test_embeddings_2 = fine_tuned_model.encode([example.texts[1] for example in test_samples], \n",
    "                                            convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity between pairs of embeddings\n",
    "    cosine_similarities = [F.cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item() \n",
    "                           for embedding1, embedding2 in zip(test_embeddings_1, test_embeddings_2)]\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Initialize lists to store accuracy for each threshold\n",
    "    accuracies = []\n",
    "    \n",
    "    # Loop through each threshold\n",
    "    for threshold in thresholds:\n",
    "        # Classify based on cosine similarity and the current threshold\n",
    "        predictions = [1 if cosine_sim > threshold else 0 for cosine_sim in cosine_similarities]\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        \n",
    "        # Append accuracy to the list\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Plot the accuracy for different thresholds\n",
    "    plt.plot(thresholds, accuracies)\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the accuracy plot\n",
    "    plot_path = os.path.join(eval_path, 'accuracy_plot.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Find the best threshold\n",
    "    best_threshold = thresholds[np.argmax(accuracies)]\n",
    "    print(\"Threshold with highest accuracy:\", best_threshold)\n",
    "    \n",
    "    # Classify based on cosine similarity (for example, using the best threshold)\n",
    "    predictions = [1 if cosine_sim > best_threshold else 0 for cosine_sim in cosine_similarities]\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    \n",
    "    # Compute other classification metrics\n",
    "    classification_metrics = classification_report(true_labels, predictions)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Metrics:\\n\", classification_metrics)\n",
    "    \n",
    "    # Save the classification metrics\n",
    "    metrics_path = os.path.join(eval_path, 'classification_metrics.txt')\n",
    "    with open(metrics_path, 'w') as file:\n",
    "        file.write(f\"Threshold with highest accuracy: {best_threshold}\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
    "        file.write(\"Classification Metrics:\\n\")\n",
    "        file.write(classification_metrics)\n",
    "    print(f\"Classification metrics saved to {metrics_path}\")\n",
    "    print(f\"Accuracy plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7775771-be12-4d46-b9f8-6b73491ae0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data_names = []\n",
    "model_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c73249-566b-4d1e-ae28-752d95b8052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing dataset 1 of 1 on model 1 of 1: google/electra-base-discriminator\n",
      "PyTorch version: 2.4.0+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Available devices:\n",
      "1\n",
      "  Device 0: NVIDIA RTX 6000 Ada Generation\n",
      "Using device: cuda\n",
      "2024-08-01 21:01:06 - Load pretrained SentenceTransformer: google/electra-base-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 21:01:06 - No sentence-transformers model found with name /home/user/.cache/torch/sentence_transformers/google_electra-base-discriminator. Creating a new one with MEAN pooling.\n",
      "2024-08-01 21:01:06 - Use pytorch device: cuda\n",
      "2024-08-01 21:01:06 - Load pretrained SentenceTransformer: google/electra-base-discriminator\n",
      "2024-08-01 21:01:07 - No sentence-transformers model found with name /home/user/.cache/torch/sentence_transformers/google_electra-base-discriminator. Creating a new one with MEAN pooling.\n",
      "2024-08-01 21:01:07 - Use pytorch device: cuda\n",
      "processing i 0\n",
      "processing i 1000\n",
      "processing i 2000\n",
      "processing i 3000\n",
      "processing i 4000\n",
      "processing i 5000\n",
      "processing i 6000\n",
      "processing i 7000\n",
      "processing i 8000\n",
      "processing i 9000\n",
      "processing i 10000\n",
      "processing i 11000\n",
      "processing i 12000\n",
      "processing i 13000\n",
      "processing i 14000\n",
      "processing i 15000\n",
      "processing i 16000\n",
      "processing i 17000\n",
      "processing i 18000\n",
      "processing i 19000\n",
      "processing i 20000\n",
      "processing i 21000\n",
      "processing i 22000\n",
      "processing i 23000\n",
      "processing i 24000\n",
      "processing i 25000\n",
      "processing i 26000\n",
      "processing i 27000\n",
      "processing i 28000\n",
      "processing i 29000\n",
      "processing i 30000\n",
      "processing i 31000\n",
      "processing i 32000\n",
      "processing i 33000\n",
      "processing i 34000\n",
      "processing i 35000\n",
      "processing i 36000\n",
      "processing i 37000\n",
      "processing i 38000\n",
      "processing i 39000\n",
      "processing i 40000\n",
      "processing i 41000\n",
      "processing i 42000\n",
      "processing i 43000\n",
      "processing i 44000\n",
      "processing i 45000\n",
      "processing i 46000\n",
      "processing i 47000\n",
      "processing i 48000\n",
      "processing i 49000\n",
      "processing i 50000\n",
      "processing i 51000\n",
      "processing i 52000\n",
      "processing i 53000\n",
      "processing i 54000\n",
      "processing i 55000\n",
      "processing i 56000\n",
      "processing i 57000\n",
      "processing i 58000\n",
      "processing i 59000\n",
      "processing i 60000\n",
      "processing i 61000\n",
      "processing i 62000\n",
      "processing i 63000\n",
      "processing i 64000\n",
      "processing i 65000\n",
      "processing i 66000\n",
      "processing i 67000\n",
      "processing i 68000\n",
      "processing i 69000\n",
      "processing i 70000\n",
      "processing i 71000\n",
      "processing i 72000\n",
      "processing i 73000\n",
      "processing i 74000\n",
      "processing i 75000\n",
      "processing i 76000\n",
      "processing i 77000\n",
      "processing i 78000\n",
      "processing i 79000\n",
      "processing i 80000\n",
      "processing i 81000\n",
      "processing i 82000\n",
      "processing i 83000\n",
      "processing i 84000\n",
      "processing i 85000\n",
      "processing i 86000\n",
      "processing i 87000\n",
      "processing i 88000\n",
      "processing i 89000\n",
      "processing i 90000\n",
      "processing i 0\n",
      "processing i 1000\n",
      "processing i 2000\n",
      "processing i 3000\n",
      "processing i 4000\n",
      "processing i 5000\n",
      "processing i 6000\n",
      "processing i 7000\n",
      "processing i 8000\n",
      "processing i 9000\n",
      "processing i 10000\n",
      "processing i 11000\n",
      "processing i 12000\n",
      "processing i 0\n",
      "processing i 1000\n",
      "processing i 2000\n",
      "processing i 3000\n",
      "processing i 4000\n",
      "processing i 5000\n",
      "processing i 6000\n",
      "processing i 7000\n",
      "processing i 8000\n",
      "processing i 9000\n",
      "processing i 10000\n",
      "processing i 11000\n",
      "processing i 12000\n",
      "processing i 13000\n",
      "processing i 14000\n",
      "processing i 15000\n",
      "processing i 16000\n",
      "processing i 17000\n",
      "processing i 18000\n",
      "processing i 19000\n",
      "processing i 20000\n",
      "processing i 21000\n",
      "processing i 22000\n",
      "processing i 23000\n",
      "processing i 24000\n",
      "processing i 25000\n",
      "2024-08-01 21:30:06 - Warmup-steps: 1132\n",
      "2024-08-01 21:30:06 - Steps per epoch: 2830\n",
      "2024-08-01 21:30:06 - Evaluation steps: 283\n",
      "Checking DataLoader\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc34ec2a528445eaa17bae57f84b80bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2b3551a2f34ae682db58ed7e9de795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 21:32:17 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 283 steps:\n",
      "2024-08-01 21:33:35 - Cosine-Similarity :\tPearson: 0.0083\tSpearman: 0.0106\n",
      "2024-08-01 21:33:35 - Manhattan-Distance:\tPearson: 0.0167\tSpearman: 0.0175\n",
      "2024-08-01 21:33:35 - Euclidean-Distance:\tPearson: 0.0096\tSpearman: 0.0116\n",
      "2024-08-01 21:33:35 - Dot-Product-Similarity:\tPearson: 0.0044\tSpearman: 0.0003\n",
      "2024-08-01 21:33:35 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:35:51 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 566 steps:\n",
      "2024-08-01 21:37:10 - Cosine-Similarity :\tPearson: 0.0439\tSpearman: 0.0465\n",
      "2024-08-01 21:37:10 - Manhattan-Distance:\tPearson: 0.0370\tSpearman: 0.0433\n",
      "2024-08-01 21:37:10 - Euclidean-Distance:\tPearson: 0.0358\tSpearman: 0.0365\n",
      "2024-08-01 21:37:10 - Dot-Product-Similarity:\tPearson: 0.0413\tSpearman: 0.0429\n",
      "2024-08-01 21:37:10 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:39:27 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 849 steps:\n",
      "2024-08-01 21:40:46 - Cosine-Similarity :\tPearson: 0.3454\tSpearman: 0.3282\n",
      "2024-08-01 21:40:46 - Manhattan-Distance:\tPearson: 0.3390\tSpearman: 0.3274\n",
      "2024-08-01 21:40:46 - Euclidean-Distance:\tPearson: 0.3298\tSpearman: 0.3157\n",
      "2024-08-01 21:40:46 - Dot-Product-Similarity:\tPearson: 0.3464\tSpearman: 0.3305\n",
      "2024-08-01 21:40:46 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:43:04 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 1132 steps:\n",
      "2024-08-01 21:44:23 - Cosine-Similarity :\tPearson: 0.4870\tSpearman: 0.4678\n",
      "2024-08-01 21:44:23 - Manhattan-Distance:\tPearson: 0.5014\tSpearman: 0.4790\n",
      "2024-08-01 21:44:23 - Euclidean-Distance:\tPearson: 0.4909\tSpearman: 0.4693\n",
      "2024-08-01 21:44:23 - Dot-Product-Similarity:\tPearson: 0.4724\tSpearman: 0.4515\n",
      "2024-08-01 21:44:23 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:46:40 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 1415 steps:\n",
      "2024-08-01 21:47:59 - Cosine-Similarity :\tPearson: 0.5945\tSpearman: 0.5744\n",
      "2024-08-01 21:47:59 - Manhattan-Distance:\tPearson: 0.5852\tSpearman: 0.5711\n",
      "2024-08-01 21:47:59 - Euclidean-Distance:\tPearson: 0.5881\tSpearman: 0.5744\n",
      "2024-08-01 21:47:59 - Dot-Product-Similarity:\tPearson: 0.5806\tSpearman: 0.5693\n",
      "2024-08-01 21:47:59 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:50:15 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 1698 steps:\n",
      "2024-08-01 21:51:33 - Cosine-Similarity :\tPearson: 0.7073\tSpearman: 0.6841\n",
      "2024-08-01 21:51:33 - Manhattan-Distance:\tPearson: 0.7000\tSpearman: 0.6832\n",
      "2024-08-01 21:51:33 - Euclidean-Distance:\tPearson: 0.7028\tSpearman: 0.6854\n",
      "2024-08-01 21:51:33 - Dot-Product-Similarity:\tPearson: 0.6892\tSpearman: 0.6699\n",
      "2024-08-01 21:51:33 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:53:50 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 1981 steps:\n",
      "2024-08-01 21:55:08 - Cosine-Similarity :\tPearson: 0.7693\tSpearman: 0.7462\n",
      "2024-08-01 21:55:08 - Manhattan-Distance:\tPearson: 0.7673\tSpearman: 0.7468\n",
      "2024-08-01 21:55:08 - Euclidean-Distance:\tPearson: 0.7673\tSpearman: 0.7466\n",
      "2024-08-01 21:55:08 - Dot-Product-Similarity:\tPearson: 0.7530\tSpearman: 0.7319\n",
      "2024-08-01 21:55:08 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 21:57:25 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 2264 steps:\n",
      "2024-08-01 21:58:43 - Cosine-Similarity :\tPearson: 0.7941\tSpearman: 0.7639\n",
      "2024-08-01 21:58:43 - Manhattan-Distance:\tPearson: 0.7869\tSpearman: 0.7635\n",
      "2024-08-01 21:58:43 - Euclidean-Distance:\tPearson: 0.7874\tSpearman: 0.7637\n",
      "2024-08-01 21:58:43 - Dot-Product-Similarity:\tPearson: 0.7803\tSpearman: 0.7532\n",
      "2024-08-01 21:58:43 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:00:59 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 2547 steps:\n",
      "2024-08-01 22:02:17 - Cosine-Similarity :\tPearson: 0.8223\tSpearman: 0.7859\n",
      "2024-08-01 22:02:17 - Manhattan-Distance:\tPearson: 0.8144\tSpearman: 0.7852\n",
      "2024-08-01 22:02:17 - Euclidean-Distance:\tPearson: 0.8151\tSpearman: 0.7856\n",
      "2024-08-01 22:02:17 - Dot-Product-Similarity:\tPearson: 0.8095\tSpearman: 0.7768\n",
      "2024-08-01 22:02:17 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:04:34 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 0 after 2830 steps:\n",
      "2024-08-01 22:05:52 - Cosine-Similarity :\tPearson: 0.8450\tSpearman: 0.8021\n",
      "2024-08-01 22:05:52 - Manhattan-Distance:\tPearson: 0.8376\tSpearman: 0.8042\n",
      "2024-08-01 22:05:52 - Euclidean-Distance:\tPearson: 0.8381\tSpearman: 0.8045\n",
      "2024-08-01 22:05:52 - Dot-Product-Similarity:\tPearson: 0.8248\tSpearman: 0.7889\n",
      "2024-08-01 22:05:52 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:05:53 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset after epoch 0:\n",
      "2024-08-01 22:07:12 - Cosine-Similarity :\tPearson: 0.8450\tSpearman: 0.8021\n",
      "2024-08-01 22:07:12 - Manhattan-Distance:\tPearson: 0.8376\tSpearman: 0.8042\n",
      "2024-08-01 22:07:12 - Euclidean-Distance:\tPearson: 0.8381\tSpearman: 0.8045\n",
      "2024-08-01 22:07:12 - Dot-Product-Similarity:\tPearson: 0.8248\tSpearman: 0.7889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24864893b690470e97406d220352133a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 22:09:29 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 283 steps:\n",
      "2024-08-01 22:10:47 - Cosine-Similarity :\tPearson: 0.8579\tSpearman: 0.8115\n",
      "2024-08-01 22:10:47 - Manhattan-Distance:\tPearson: 0.8491\tSpearman: 0.8122\n",
      "2024-08-01 22:10:47 - Euclidean-Distance:\tPearson: 0.8490\tSpearman: 0.8121\n",
      "2024-08-01 22:10:47 - Dot-Product-Similarity:\tPearson: 0.8346\tSpearman: 0.7988\n",
      "2024-08-01 22:10:47 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:13:06 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 566 steps:\n",
      "2024-08-01 22:14:25 - Cosine-Similarity :\tPearson: 0.8664\tSpearman: 0.8170\n",
      "2024-08-01 22:14:25 - Manhattan-Distance:\tPearson: 0.8577\tSpearman: 0.8175\n",
      "2024-08-01 22:14:25 - Euclidean-Distance:\tPearson: 0.8579\tSpearman: 0.8176\n",
      "2024-08-01 22:14:25 - Dot-Product-Similarity:\tPearson: 0.8431\tSpearman: 0.8044\n",
      "2024-08-01 22:14:25 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:16:42 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 849 steps:\n",
      "2024-08-01 22:18:00 - Cosine-Similarity :\tPearson: 0.8772\tSpearman: 0.8222\n",
      "2024-08-01 22:18:00 - Manhattan-Distance:\tPearson: 0.8664\tSpearman: 0.8232\n",
      "2024-08-01 22:18:00 - Euclidean-Distance:\tPearson: 0.8670\tSpearman: 0.8234\n",
      "2024-08-01 22:18:00 - Dot-Product-Similarity:\tPearson: 0.8487\tSpearman: 0.8088\n",
      "2024-08-01 22:18:00 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:20:16 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 1132 steps:\n",
      "2024-08-01 22:21:34 - Cosine-Similarity :\tPearson: 0.8833\tSpearman: 0.8260\n",
      "2024-08-01 22:21:34 - Manhattan-Distance:\tPearson: 0.8751\tSpearman: 0.8277\n",
      "2024-08-01 22:21:34 - Euclidean-Distance:\tPearson: 0.8753\tSpearman: 0.8278\n",
      "2024-08-01 22:21:34 - Dot-Product-Similarity:\tPearson: 0.8566\tSpearman: 0.8132\n",
      "2024-08-01 22:21:34 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:23:50 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 1415 steps:\n",
      "2024-08-01 22:25:08 - Cosine-Similarity :\tPearson: 0.8957\tSpearman: 0.8314\n",
      "2024-08-01 22:25:08 - Manhattan-Distance:\tPearson: 0.8845\tSpearman: 0.8322\n",
      "2024-08-01 22:25:08 - Euclidean-Distance:\tPearson: 0.8850\tSpearman: 0.8324\n",
      "2024-08-01 22:25:08 - Dot-Product-Similarity:\tPearson: 0.8693\tSpearman: 0.8207\n",
      "2024-08-01 22:25:08 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:27:24 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 1698 steps:\n",
      "2024-08-01 22:28:42 - Cosine-Similarity :\tPearson: 0.8930\tSpearman: 0.8304\n",
      "2024-08-01 22:28:42 - Manhattan-Distance:\tPearson: 0.8816\tSpearman: 0.8302\n",
      "2024-08-01 22:28:42 - Euclidean-Distance:\tPearson: 0.8819\tSpearman: 0.8303\n",
      "2024-08-01 22:28:42 - Dot-Product-Similarity:\tPearson: 0.8645\tSpearman: 0.8176\n",
      "2024-08-01 22:30:57 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 1981 steps:\n",
      "2024-08-01 22:32:15 - Cosine-Similarity :\tPearson: 0.9012\tSpearman: 0.8342\n",
      "2024-08-01 22:32:15 - Manhattan-Distance:\tPearson: 0.8891\tSpearman: 0.8348\n",
      "2024-08-01 22:32:15 - Euclidean-Distance:\tPearson: 0.8896\tSpearman: 0.8351\n",
      "2024-08-01 22:32:15 - Dot-Product-Similarity:\tPearson: 0.8712\tSpearman: 0.8223\n",
      "2024-08-01 22:32:15 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:34:32 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 2264 steps:\n",
      "2024-08-01 22:35:51 - Cosine-Similarity :\tPearson: 0.9070\tSpearman: 0.8381\n",
      "2024-08-01 22:35:51 - Manhattan-Distance:\tPearson: 0.8967\tSpearman: 0.8381\n",
      "2024-08-01 22:35:51 - Euclidean-Distance:\tPearson: 0.8970\tSpearman: 0.8382\n",
      "2024-08-01 22:35:51 - Dot-Product-Similarity:\tPearson: 0.8788\tSpearman: 0.8272\n",
      "2024-08-01 22:35:51 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:38:09 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 2547 steps:\n",
      "2024-08-01 22:39:28 - Cosine-Similarity :\tPearson: 0.9091\tSpearman: 0.8391\n",
      "2024-08-01 22:39:28 - Manhattan-Distance:\tPearson: 0.9008\tSpearman: 0.8400\n",
      "2024-08-01 22:39:28 - Euclidean-Distance:\tPearson: 0.9011\tSpearman: 0.8400\n",
      "2024-08-01 22:39:28 - Dot-Product-Similarity:\tPearson: 0.8808\tSpearman: 0.8279\n",
      "2024-08-01 22:39:28 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:41:45 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 1 after 2830 steps:\n",
      "2024-08-01 22:43:03 - Cosine-Similarity :\tPearson: 0.9117\tSpearman: 0.8393\n",
      "2024-08-01 22:43:04 - Manhattan-Distance:\tPearson: 0.8997\tSpearman: 0.8394\n",
      "2024-08-01 22:43:04 - Euclidean-Distance:\tPearson: 0.9002\tSpearman: 0.8396\n",
      "2024-08-01 22:43:04 - Dot-Product-Similarity:\tPearson: 0.8809\tSpearman: 0.8282\n",
      "2024-08-01 22:43:04 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset after epoch 1:\n",
      "2024-08-01 22:44:21 - Cosine-Similarity :\tPearson: 0.9117\tSpearman: 0.8393\n",
      "2024-08-01 22:44:21 - Manhattan-Distance:\tPearson: 0.8997\tSpearman: 0.8394\n",
      "2024-08-01 22:44:21 - Euclidean-Distance:\tPearson: 0.9002\tSpearman: 0.8396\n",
      "2024-08-01 22:44:21 - Dot-Product-Similarity:\tPearson: 0.8809\tSpearman: 0.8282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636c6955bc54446ba2d74c3a45a609f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 22:46:36 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 283 steps:\n",
      "2024-08-01 22:47:54 - Cosine-Similarity :\tPearson: 0.9145\tSpearman: 0.8404\n",
      "2024-08-01 22:47:54 - Manhattan-Distance:\tPearson: 0.9020\tSpearman: 0.8405\n",
      "2024-08-01 22:47:54 - Euclidean-Distance:\tPearson: 0.9025\tSpearman: 0.8407\n",
      "2024-08-01 22:47:54 - Dot-Product-Similarity:\tPearson: 0.8866\tSpearman: 0.8312\n",
      "2024-08-01 22:47:54 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:50:10 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 566 steps:\n",
      "2024-08-01 22:51:29 - Cosine-Similarity :\tPearson: 0.9152\tSpearman: 0.8407\n",
      "2024-08-01 22:51:29 - Manhattan-Distance:\tPearson: 0.9015\tSpearman: 0.8407\n",
      "2024-08-01 22:51:29 - Euclidean-Distance:\tPearson: 0.9020\tSpearman: 0.8409\n",
      "2024-08-01 22:51:29 - Dot-Product-Similarity:\tPearson: 0.8840\tSpearman: 0.8299\n",
      "2024-08-01 22:51:29 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:53:45 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 849 steps:\n",
      "2024-08-01 22:55:03 - Cosine-Similarity :\tPearson: 0.9199\tSpearman: 0.8432\n",
      "2024-08-01 22:55:03 - Manhattan-Distance:\tPearson: 0.9100\tSpearman: 0.8432\n",
      "2024-08-01 22:55:03 - Euclidean-Distance:\tPearson: 0.9104\tSpearman: 0.8433\n",
      "2024-08-01 22:55:03 - Dot-Product-Similarity:\tPearson: 0.8890\tSpearman: 0.8310\n",
      "2024-08-01 22:55:03 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 22:57:18 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 1132 steps:\n",
      "2024-08-01 22:58:36 - Cosine-Similarity :\tPearson: 0.9198\tSpearman: 0.8417\n",
      "2024-08-01 22:58:36 - Manhattan-Distance:\tPearson: 0.9087\tSpearman: 0.8421\n",
      "2024-08-01 22:58:36 - Euclidean-Distance:\tPearson: 0.9091\tSpearman: 0.8422\n",
      "2024-08-01 22:58:36 - Dot-Product-Similarity:\tPearson: 0.8900\tSpearman: 0.8305\n",
      "2024-08-01 23:00:52 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 1415 steps:\n",
      "2024-08-01 23:02:11 - Cosine-Similarity :\tPearson: 0.9221\tSpearman: 0.8437\n",
      "2024-08-01 23:02:11 - Manhattan-Distance:\tPearson: 0.9093\tSpearman: 0.8436\n",
      "2024-08-01 23:02:11 - Euclidean-Distance:\tPearson: 0.9097\tSpearman: 0.8437\n",
      "2024-08-01 23:02:11 - Dot-Product-Similarity:\tPearson: 0.8911\tSpearman: 0.8338\n",
      "2024-08-01 23:02:11 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 23:04:29 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 1698 steps:\n",
      "2024-08-01 23:05:47 - Cosine-Similarity :\tPearson: 0.9243\tSpearman: 0.8433\n",
      "2024-08-01 23:05:47 - Manhattan-Distance:\tPearson: 0.9124\tSpearman: 0.8435\n",
      "2024-08-01 23:05:47 - Euclidean-Distance:\tPearson: 0.9128\tSpearman: 0.8437\n",
      "2024-08-01 23:05:47 - Dot-Product-Similarity:\tPearson: 0.8924\tSpearman: 0.8333\n",
      "2024-08-01 23:08:04 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 1981 steps:\n",
      "2024-08-01 23:09:23 - Cosine-Similarity :\tPearson: 0.9230\tSpearman: 0.8441\n",
      "2024-08-01 23:09:23 - Manhattan-Distance:\tPearson: 0.9142\tSpearman: 0.8445\n",
      "2024-08-01 23:09:23 - Euclidean-Distance:\tPearson: 0.9147\tSpearman: 0.8447\n",
      "2024-08-01 23:09:23 - Dot-Product-Similarity:\tPearson: 0.8923\tSpearman: 0.8319\n",
      "2024-08-01 23:09:23 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 23:11:39 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 2264 steps:\n",
      "2024-08-01 23:12:58 - Cosine-Similarity :\tPearson: 0.9272\tSpearman: 0.8456\n",
      "2024-08-01 23:12:58 - Manhattan-Distance:\tPearson: 0.9160\tSpearman: 0.8458\n",
      "2024-08-01 23:12:58 - Euclidean-Distance:\tPearson: 0.9165\tSpearman: 0.8459\n",
      "2024-08-01 23:12:58 - Dot-Product-Similarity:\tPearson: 0.8943\tSpearman: 0.8343\n",
      "2024-08-01 23:12:58 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 23:15:13 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 2547 steps:\n",
      "2024-08-01 23:16:31 - Cosine-Similarity :\tPearson: 0.9274\tSpearman: 0.8452\n",
      "2024-08-01 23:16:31 - Manhattan-Distance:\tPearson: 0.9139\tSpearman: 0.8451\n",
      "2024-08-01 23:16:31 - Euclidean-Distance:\tPearson: 0.9144\tSpearman: 0.8452\n",
      "2024-08-01 23:16:31 - Dot-Product-Similarity:\tPearson: 0.8969\tSpearman: 0.8355\n",
      "2024-08-01 23:18:46 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 2 after 2830 steps:\n",
      "2024-08-01 23:20:04 - Cosine-Similarity :\tPearson: 0.9291\tSpearman: 0.8459\n",
      "2024-08-01 23:20:04 - Manhattan-Distance:\tPearson: 0.9150\tSpearman: 0.8454\n",
      "2024-08-01 23:20:04 - Euclidean-Distance:\tPearson: 0.9155\tSpearman: 0.8456\n",
      "2024-08-01 23:20:04 - Dot-Product-Similarity:\tPearson: 0.8956\tSpearman: 0.8358\n",
      "2024-08-01 23:20:04 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset after epoch 2:\n",
      "2024-08-01 23:21:22 - Cosine-Similarity :\tPearson: 0.9291\tSpearman: 0.8459\n",
      "2024-08-01 23:21:22 - Manhattan-Distance:\tPearson: 0.9150\tSpearman: 0.8454\n",
      "2024-08-01 23:21:22 - Euclidean-Distance:\tPearson: 0.9155\tSpearman: 0.8456\n",
      "2024-08-01 23:21:22 - Dot-Product-Similarity:\tPearson: 0.8956\tSpearman: 0.8358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4e002c6e6e475c947fb5cd959bbeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 23:23:36 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 283 steps:\n",
      "2024-08-01 23:24:54 - Cosine-Similarity :\tPearson: 0.9315\tSpearman: 0.8471\n",
      "2024-08-01 23:24:54 - Manhattan-Distance:\tPearson: 0.9185\tSpearman: 0.8469\n",
      "2024-08-01 23:24:54 - Euclidean-Distance:\tPearson: 0.9191\tSpearman: 0.8470\n",
      "2024-08-01 23:24:54 - Dot-Product-Similarity:\tPearson: 0.9003\tSpearman: 0.8376\n",
      "2024-08-01 23:24:54 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 23:27:10 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 566 steps:\n",
      "2024-08-01 23:28:29 - Cosine-Similarity :\tPearson: 0.9309\tSpearman: 0.8469\n",
      "2024-08-01 23:28:29 - Manhattan-Distance:\tPearson: 0.9185\tSpearman: 0.8468\n",
      "2024-08-01 23:28:29 - Euclidean-Distance:\tPearson: 0.9191\tSpearman: 0.8470\n",
      "2024-08-01 23:28:29 - Dot-Product-Similarity:\tPearson: 0.9001\tSpearman: 0.8370\n",
      "2024-08-01 23:30:45 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 849 steps:\n",
      "2024-08-01 23:32:04 - Cosine-Similarity :\tPearson: 0.9313\tSpearman: 0.8469\n",
      "2024-08-01 23:32:04 - Manhattan-Distance:\tPearson: 0.9192\tSpearman: 0.8468\n",
      "2024-08-01 23:32:04 - Euclidean-Distance:\tPearson: 0.9196\tSpearman: 0.8470\n",
      "2024-08-01 23:32:04 - Dot-Product-Similarity:\tPearson: 0.9006\tSpearman: 0.8372\n",
      "2024-08-01 23:34:21 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 1132 steps:\n",
      "2024-08-01 23:35:39 - Cosine-Similarity :\tPearson: 0.9325\tSpearman: 0.8470\n",
      "2024-08-01 23:35:39 - Manhattan-Distance:\tPearson: 0.9194\tSpearman: 0.8466\n",
      "2024-08-01 23:35:39 - Euclidean-Distance:\tPearson: 0.9199\tSpearman: 0.8468\n",
      "2024-08-01 23:35:39 - Dot-Product-Similarity:\tPearson: 0.9026\tSpearman: 0.8381\n",
      "2024-08-01 23:37:57 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 1415 steps:\n",
      "2024-08-01 23:39:16 - Cosine-Similarity :\tPearson: 0.9332\tSpearman: 0.8479\n",
      "2024-08-01 23:39:16 - Manhattan-Distance:\tPearson: 0.9205\tSpearman: 0.8475\n",
      "2024-08-01 23:39:16 - Euclidean-Distance:\tPearson: 0.9210\tSpearman: 0.8477\n",
      "2024-08-01 23:39:16 - Dot-Product-Similarity:\tPearson: 0.9026\tSpearman: 0.8390\n",
      "2024-08-01 23:39:16 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 23:41:34 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 1698 steps:\n",
      "2024-08-01 23:42:53 - Cosine-Similarity :\tPearson: 0.9333\tSpearman: 0.8470\n",
      "2024-08-01 23:42:53 - Manhattan-Distance:\tPearson: 0.9198\tSpearman: 0.8466\n",
      "2024-08-01 23:42:53 - Euclidean-Distance:\tPearson: 0.9203\tSpearman: 0.8468\n",
      "2024-08-01 23:42:53 - Dot-Product-Similarity:\tPearson: 0.9003\tSpearman: 0.8374\n",
      "2024-08-01 23:45:09 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 1981 steps:\n",
      "2024-08-01 23:46:27 - Cosine-Similarity :\tPearson: 0.9343\tSpearman: 0.8478\n",
      "2024-08-01 23:46:27 - Manhattan-Distance:\tPearson: 0.9221\tSpearman: 0.8477\n",
      "2024-08-01 23:46:27 - Euclidean-Distance:\tPearson: 0.9226\tSpearman: 0.8478\n",
      "2024-08-01 23:46:27 - Dot-Product-Similarity:\tPearson: 0.9028\tSpearman: 0.8382\n",
      "2024-08-01 23:48:42 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 2264 steps:\n",
      "2024-08-01 23:50:00 - Cosine-Similarity :\tPearson: 0.9347\tSpearman: 0.8476\n",
      "2024-08-01 23:50:00 - Manhattan-Distance:\tPearson: 0.9218\tSpearman: 0.8474\n",
      "2024-08-01 23:50:00 - Euclidean-Distance:\tPearson: 0.9223\tSpearman: 0.8475\n",
      "2024-08-01 23:50:00 - Dot-Product-Similarity:\tPearson: 0.9046\tSpearman: 0.8388\n",
      "2024-08-01 23:52:16 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 2547 steps:\n",
      "2024-08-01 23:53:34 - Cosine-Similarity :\tPearson: 0.9346\tSpearman: 0.8477\n",
      "2024-08-01 23:53:34 - Manhattan-Distance:\tPearson: 0.9221\tSpearman: 0.8474\n",
      "2024-08-01 23:53:34 - Euclidean-Distance:\tPearson: 0.9226\tSpearman: 0.8476\n",
      "2024-08-01 23:53:34 - Dot-Product-Similarity:\tPearson: 0.9042\tSpearman: 0.8387\n",
      "2024-08-01 23:55:49 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset in epoch 3 after 2830 steps:\n",
      "2024-08-01 23:57:07 - Cosine-Similarity :\tPearson: 0.9347\tSpearman: 0.8479\n",
      "2024-08-01 23:57:07 - Manhattan-Distance:\tPearson: 0.9230\tSpearman: 0.8477\n",
      "2024-08-01 23:57:07 - Euclidean-Distance:\tPearson: 0.9234\tSpearman: 0.8479\n",
      "2024-08-01 23:57:07 - Dot-Product-Similarity:\tPearson: 0.9041\tSpearman: 0.8385\n",
      "2024-08-01 23:57:07 - Save model to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06\n",
      "2024-08-01 23:57:08 - EmbeddingSimilarityEvaluator: Evaluating the model on validation dataset after epoch 3:\n",
      "2024-08-01 23:58:26 - Cosine-Similarity :\tPearson: 0.9347\tSpearman: 0.8479\n",
      "2024-08-01 23:58:26 - Manhattan-Distance:\tPearson: 0.9230\tSpearman: 0.8477\n",
      "2024-08-01 23:58:26 - Euclidean-Distance:\tPearson: 0.9234\tSpearman: 0.8479\n",
      "2024-08-01 23:58:26 - Dot-Product-Similarity:\tPearson: 0.9041\tSpearman: 0.8385\n",
      "2024-08-01 23:58:26 - EmbeddingSimilarityEvaluator: Evaluating the model on model-evaluation dataset:\n",
      "2024-08-02 00:00:49 - Cosine-Similarity :\tPearson: 0.0108\tSpearman: 0.0175\n",
      "2024-08-02 00:00:49 - Manhattan-Distance:\tPearson: 0.0230\tSpearman: 0.0266\n",
      "2024-08-02 00:00:49 - Euclidean-Distance:\tPearson: 0.0122\tSpearman: 0.0163\n",
      "2024-08-02 00:00:49 - Dot-Product-Similarity:\tPearson: 0.0089\tSpearman: 0.0084\n",
      "2024-08-02 00:00:49 - EmbeddingSimilarityEvaluator: Evaluating the model on model-evaluation dataset:\n",
      "2024-08-02 00:03:28 - Cosine-Similarity :\tPearson: 0.9331\tSpearman: 0.8484\n",
      "2024-08-02 00:03:28 - Manhattan-Distance:\tPearson: 0.9233\tSpearman: 0.8491\n",
      "2024-08-02 00:03:28 - Euclidean-Distance:\tPearson: 0.9238\tSpearman: 0.8492\n",
      "2024-08-02 00:03:28 - Dot-Product-Similarity:\tPearson: 0.9007\tSpearman: 0.8367\n",
      "Original model results:\n",
      "0.026638313853310194\n",
      "Fine-tuned model results:\n",
      "0.8492147387441599\n",
      "Results saved to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06/eval/original_vs_tuned.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873d5bb0414d4bc38577ee9d3e506290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1519ec0206b64e85b04b46e2277d9c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold with highest accuracy: 0.5555555555555556\n",
      "Accuracy: 0.9652120134513548\n",
      "Classification Metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96     12932\n",
      "         1.0       0.95      0.98      0.97     12939\n",
      "\n",
      "    accuracy                           0.97     25871\n",
      "   macro avg       0.97      0.97      0.97     25871\n",
      "weighted avg       0.97      0.97      0.97     25871\n",
      "\n",
      "Classification metrics saved to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06/eval/classification_metrics.txt\n",
      "Accuracy plot saved to good_code/fine_tuned_models/original_withoutNames/fine_tuning-google-electra-base-discriminator-2024-08-01_21-01-06/eval/accuracy_plot.png\n"
     ]
    }
   ],
   "source": [
    "for dataset_idx, dataset_name in enumerate(set_data_names):\n",
    "    for model_idx, model_name in enumerate(model_names):\n",
    "        # Show progress\n",
    "        print(f\"Now doing dataset {dataset_idx + 1} of {len(set_data_names)} on model {model_idx + 1} of {len(model_names)}: {model_name}\")\n",
    "        \n",
    "        # Call the fine_tune function\n",
    "        fine_tune(model_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a83ec-a561-41b4-b0bb-56313207b61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
